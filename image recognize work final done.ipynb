{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[]\n",
    "target=[]\n",
    "with open(r'C:\\Users\\Student\\Desktop\\dataset_1\\train.csv') as dat:\n",
    "    dat.readline()\n",
    "    reader = csv.reader(dat, delimiter = ',')\n",
    "    for row in reader:\n",
    "        temp=cv2.imread(os.path.join(os.getcwd(), 'train', row[0]))\n",
    "       # temp1=cv2(temp)\n",
    "        train_data.append(temp)\n",
    "        target.append(row[1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "  print(type(train_data))\n",
    "    \n",
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n"
     ]
    }
   ],
   "source": [
    "train_data=np.array(train_data)\n",
    "train_data=train_data/255.\n",
    "target=np.array(target)\n",
    "\n",
    "uni=np.unique(target)\n",
    "print(uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = target.reshape(len(target), 1)\n",
    "Y = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_WyRytb0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a0a6d6279922>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_WyRytb0.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_WyRytb0.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data=[]\n",
    "\n",
    "with open('test_WyRytb0.csv') as dat:\n",
    "    dat.readline()\n",
    "    reader = csv.reader(dat, delimiter = ',')\n",
    "    for row in reader:\n",
    "        temp=cv2.imread(os.path.join(os.getcwd(), 'train', row[0]))\n",
    "        temp1=cv2.resize(temp, (100,100))\n",
    "        test_data.append(temp1)\n",
    "        \n",
    "        \n",
    "test_data=np.array(test_data)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(r\"C:\\\\Users\\\\Student\\\\Desktop\\\\dataset_1\\\\train\\\\0.png\")\n",
    "#imgplot = plt.imshow(img)\n",
    "dimensions = img.shape\n",
    "print(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IntelNet(input_shape = (28, 28, 3), classes = len(uni)):\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    \n",
    "     # Stage 1\n",
    "    X = Conv2D(128, (7, 7), strides = (2, 2), name = 'conv1',padding = 'SAME')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    #X = MaxPooling2D((3, 3), strides=(2, 2),padding = 'SAME')(X)\n",
    "    \n",
    "\n",
    "    X = Conv2D(128, (5, 5), strides = (1, 1), name = 'conv2')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    \n",
    "    X = Conv2D(128, (5, 5), strides = (1, 1), name = 'conv3')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(256, (3, 3), strides = (1, 1), name = 'conv4')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IntelNet(input_shape = (28, 28, 3), classes = len(uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(train_data,Y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4800/4800 [==============================] - 96s 20ms/step - loss: 0.6681 - acc: 0.8167\n",
      "Epoch 2/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 0.1407 - acc: 0.9560\n",
      "Epoch 3/100\n",
      "4800/4800 [==============================] - 91s 19ms/step - loss: 0.0909 - acc: 0.9696\n",
      "Epoch 4/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 0.0513 - acc: 0.9854\n",
      "Epoch 5/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 0.0397 - acc: 0.9900\n",
      "Epoch 6/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 0.0223 - acc: 0.9956\n",
      "Epoch 7/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 0.0100 - acc: 0.9992\n",
      "Epoch 8/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 0.0069 - acc: 0.9996\n",
      "Epoch 9/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 9.4476e-04 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 7.8080e-04 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 6.7076e-04 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 6.5639e-04 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 5.7027e-04 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 5.2403e-04 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 4.8237e-04 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 4.2095e-04 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 3.8502e-04 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 3.7252e-04 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 3.2354e-04 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.9383e-04 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.9141e-04 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.6290e-04 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.4671e-04 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.4453e-04 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.1905e-04 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.0321e-04 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.9429e-04 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.7686e-04 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.6776e-04 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.6334e-04 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.5224e-04 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.4187e-04 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.3626e-04 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.2139e-04 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.1928e-04 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.1235e-04 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.1051e-04 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.0683e-04 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.0181e-04 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 9.2764e-05 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 9.0238e-05 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 8.8611e-05 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 8.3490e-05 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 7.9447e-05 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 7.6328e-05 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 7.0301e-05 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 6.5300e-05 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 6.4264e-05 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 6.0255e-05 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 5.9238e-05 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 5.4672e-05 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 5.4427e-05 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 5.3848e-05 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 5.0856e-05 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 4.7051e-05 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 4.6261e-05 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 4.4156e-05 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 4.3445e-05 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 4.1536e-05 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 3.9177e-05 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 3.8112e-05 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 3.7764e-05 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 3.4348e-05 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 3.4296e-05 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 3.4584e-05 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 3.3148e-05 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 3.0892e-05 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.9710e-05 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 3.0408e-05 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.9720e-05 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.6633e-05 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.4425e-05 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.5496e-05 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.3852e-05 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.2528e-05 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.1344e-05 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.1675e-05 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.0495e-05 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.0696e-05 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 2.0158e-05 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.9674e-05 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.8408e-05 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.7422e-05 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.7174e-05 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.6543e-05 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "4800/4800 [==============================] - 91s 19ms/step - loss: 1.7026e-05 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.5721e-05 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.5523e-05 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.4820e-05 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.3946e-05 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.3773e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.3395e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.3149e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.2634e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.7133e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "4800/4800 [==============================] - 90s 19ms/step - loss: 1.3028e-05 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c9ceecbc18>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 100, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 5s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0762311013258755, 0.9799999957283337]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_test, y=Y_test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 4 0 ... 2 9 0]\n"
     ]
    }
   ],
   "source": [
    "probs=model.predict(X_test)\n",
    "classe=probs.argmax(axis=-1)\n",
    "print(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 34, 34, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 17, 17, 128)       18944     \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 13, 13, 128)       409728    \n",
      "_________________________________________________________________\n",
      "bn_conv2 (BatchNormalization (None, 13, 13, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 9, 9, 128)         409728    \n",
      "_________________________________________________________________\n",
      "bn_conv3 (BatchNormalization (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "bn_conv4 (BatchNormalization (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "fc10 (Dense)                 (None, 10)                23050     \n",
      "=================================================================\n",
      "Total params: 1,159,178\n",
      "Trainable params: 1,157,898\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
